{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saqibmurtaza/AI-Q2-learning-resources/blob/master/01_ai_agents_first/11_handoffs/handoffs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Handoffs\n",
        "\n",
        "Handoffs allow an agent to delegate tasks to another agent. This is particularly useful in scenarios where different agents specialize in distinct areas. For example, a customer support app might have agents that each specifically handle tasks like order status, refunds, FAQs, etc.\n",
        "\n",
        "Handoffs are represented as tools to the LLM. So if there's a handoff to an agent named Refund Agent, the tool would be called transfer_to_refund_agent.\n",
        "\n",
        "[Learning Reference](https://openai.github.io/openai-agents-python/handoffs/)"
      ],
      "metadata": {
        "id": "Gzlfa596ZzW6"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PdKwzEluDBN7"
      },
      "source": [
        "## Install openai-agents SDK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3QdkOviEB2ay"
      },
      "outputs": [],
      "source": [
        "!pip install -Uq openai-agents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yD91lz4DIAx"
      },
      "source": [
        "## Make your Notebook capable of running asynchronous functions.\n",
        "Both Jupyter notebooks and Python’s asyncio library utilize event loops, but they serve different purposes and can sometimes interfere with each other.\n",
        "\n",
        "The nest_asyncio library allows the existing event loop to accept nested event loops, enabling asyncio code to run within environments that already have an event loop, such as Jupyter notebooks.\n",
        "\n",
        "In summary, both Jupyter notebooks and Python’s asyncio library utilize event loops to manage asynchronous operations. When working within Jupyter notebooks, it’s essential to be aware of the existing event loop to effectively run asyncio code without conflicts."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ],
      "metadata": {
        "id": "C8YXyIpiZ9v4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Config"
      ],
      "metadata": {
        "id": "wQsVowow7ihQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XnusaX_RWF22"
      },
      "outputs": [],
      "source": [
        "from pydantic import BaseModel\n",
        "from agents import (\n",
        "    AsyncOpenAI,\n",
        "    OpenAIChatCompletionsModel,\n",
        "    RunConfig\n",
        ")\n",
        "from google.colab import userdata\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gemini_api_key = userdata.get(\"GEMINI_API_KEY\")\n",
        "\n",
        "\n",
        "# Check if the API key is present; if not, raise an error\n",
        "if not gemini_api_key:\n",
        "    raise ValueError(\"GEMINI_API_KEY is not set. Please ensure it is defined in your .env file.\")\n",
        "\n",
        "#Reference: https://ai.google.dev/gemini-api/docs/openai\n",
        "external_client = AsyncOpenAI(\n",
        "    api_key=gemini_api_key,\n",
        "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\",\n",
        ")\n",
        "\n",
        "model = OpenAIChatCompletionsModel(\n",
        "    model=\"gemini-2.0-flash\",\n",
        "    openai_client=external_client\n",
        ")\n",
        "\n",
        "config = RunConfig(\n",
        "    model=model,\n",
        "    model_provider=external_client,\n",
        "    tracing_disabled=True\n",
        ")"
      ],
      "metadata": {
        "id": "oPvcFwItoKqw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating a handoff\n",
        "\n",
        "All agents have a handoffs param, which can either take an Agent directly, or a Handoff object that customizes the Handoff."
      ],
      "metadata": {
        "id": "L4gdpCV3G6mL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "from agents import Agent, handoff, Runner"
      ],
      "metadata": {
        "id": "xK-Q9py2aSHq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Basic Usage"
      ],
      "metadata": {
        "id": "H69YnuGiaPcS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from agents import RunContextWrapper, Agent, handoff\n",
        "\n",
        "def on_handoff(agent: Agent, ctx: RunContextWrapper[None]):\n",
        "    print(f\"\\n+++++++++++++++++++++++\")\n",
        "    print(f\"Handoff received Agent Name : {agent.name}\")\n",
        "    print(f\"\\n***********************\")\n",
        "\n",
        "french_agent = Agent(\n",
        "    name=\"french agent\",\n",
        "    instructions=\"You translate it to french.\",\n",
        ")\n",
        "\n",
        "spanish_agent = Agent(\n",
        "    name=\"Spanish Translator agent\",\n",
        "    instructions=\"\"\"\n",
        "You are a Spanish translator. When you receive text, do the following:\n",
        "1. Translate it to Spanish.\n",
        "2. Then, hand off to the French agent to get the French translation.\n",
        "2. Show both translations to user.\n",
        "\"\"\",\n",
        "    handoff_description=\"You translate to Spanish and then send it to the French agent.\",\n",
        "    handoffs=[\n",
        "        handoff(\n",
        "            french_agent,\n",
        "            on_handoff=lambda ctx: on_handoff(french_agent, ctx),\n",
        "            tool_name_override=\"french_translation\"\n",
        "        )\n",
        "    ]\n",
        ")\n",
        "\n",
        "triage_agent = Agent(\n",
        "    name=\"Triage agent\",\n",
        "    instructions=\"Handoff to the appropriate agent based on the language of the request.\",\n",
        "    handoffs=[\n",
        "        handoff(\n",
        "            french_agent,\n",
        "            on_handoff=lambda ctx: on_handoff(french_agent, ctx),\n",
        "            tool_name_override=\"french_translation\"\n",
        "        ),\n",
        "        handoff(\n",
        "            spanish_agent,\n",
        "            on_handoff=lambda ctx: on_handoff(spanish_agent, ctx),\n",
        "            tool_name_override=\"spanish_translation\"\n",
        "        )\n",
        "    ],\n",
        ")\n",
        "\n",
        "# Assuming you have Runner and config properly set up\n",
        "async def main(input: str):\n",
        "    result = await Runner.run(triage_agent, input=input, run_config=config)\n",
        "    print(result.final_output)\n",
        "    print(result.last_agent)\n",
        "    print(result.context_wrapper)\n"
      ],
      "metadata": {
        "id": "CGt8gkA6cX6_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "asyncio.run(main('Translate \"hello\" to french'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "id": "QitpUQUrdtFV",
        "outputId": "fff63c6a-0c15-4ffe-dd0a-c14fc1a628b4"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'asyncio' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1-3075192464.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Translate \"hello\" to french'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'asyncio' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "asyncio.run(main(\"Hi\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPe1lF_SduCL",
        "outputId": "3f1c7081-c784-4750-89d0-154cb4f192c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What can I help you with?\n",
            "\n",
            "Agent(name='Triage agent', instructions='Handoff to the appropriate agent based on the language of the request.', prompt=None, handoff_description=None, handoffs=[Handoff(tool_name='french_translation', tool_description='Handoff to the french agent agent to handle the request. ', input_json_schema={'additionalProperties': False, 'type': 'object', 'properties': {}, 'required': []}, on_invoke_handoff=<function handoff.<locals>._invoke_handoff at 0x7f0ba65d9300>, agent_name='french agent', input_filter=None, strict_json_schema=True), Handoff(tool_name='spanish_translation', tool_description='Handoff to the Spanish Translator agent agent to handle the request. You translate to Spanish and then send it to the French agent.', input_json_schema={'additionalProperties': False, 'type': 'object', 'properties': {}, 'required': []}, on_invoke_handoff=<function handoff.<locals>._invoke_handoff at 0x7f0ba65d9940>, agent_name='Spanish Translator agent', input_filter=None, strict_json_schema=True)], model=None, model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, metadata=None, store=None, include_usage=None, extra_query=None, extra_body=None, extra_headers=None, extra_args=None), tools=[], mcp_servers=[], mcp_config={}, input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True)\n",
            "RunContextWrapper(context=None, usage=Usage(requests=1, input_tokens=60, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=8, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=68))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Customizing handoffs via the handoff() function"
      ],
      "metadata": {
        "id": "ueYtWnG2d19I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from agents import Agent, handoff, RunContextWrapper\n",
        "\n",
        "urdu_agent = Agent(\n",
        "    name=\"Urdu agent\",\n",
        "    instructions=\"You only speak Urdu.\"\n",
        ")\n",
        "\n",
        "english_agent = Agent(\n",
        "    name=\"English agent\",\n",
        "    instructions=\"You only speak English\"\n",
        ")\n",
        "\n",
        "def on_handoff(agent: Agent, ctx: RunContextWrapper[None]):\n",
        "    agent_name = agent.name\n",
        "    print(\"--------------------------------\")\n",
        "    print(f\"Handing off to {agent_name}...\")\n",
        "    print(\"--------------------------------\")\n",
        "\n",
        "triage_agent = Agent(\n",
        "    name=\"Triage agent\",\n",
        "    instructions=\"Handoff to the appropriate agent based on the language of the request.\",\n",
        "    handoffs=[\n",
        "            handoff(urdu_agent, on_handoff=lambda ctx: on_handoff(urdu_agent, ctx)),\n",
        "            handoff(english_agent, on_handoff=lambda ctx: on_handoff(english_agent, ctx))\n",
        "    ],\n",
        ")\n",
        "\n",
        "\n",
        "async def main(input: str):\n",
        "    result = await Runner.run(triage_agent, input=input, run_config=config)\n",
        "    print(result.final_output)\n"
      ],
      "metadata": {
        "id": "M50noPNyd9e6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "asyncio.run(main(\"السلام عليكم\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lbTE7uxNeT78",
        "outputId": "aa5c1d5c-3489-4ba4-a2fa-112da2146b1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------\n",
            "Handing off to Urdu agent...\n",
            "--------------------------------\n",
            "وعلیکم السلام! آپ کیسے ہیں؟ میں آپ کی کیا مدد کرسکتا ہوں؟\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "asyncio.run(main(\"Hello, nice to meet you\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6X9XqQPeV_A",
        "outputId": "f369bb56-c2ab-4a85-e663-43075a59708d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nice to meet you too! How can I help you today?\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Self Assignment\n",
        "\n",
        "Implement the following with HandOffs Pattern:\n",
        "- Handoff Custom Inputs\n",
        "- Set an input_filter\n",
        "- Share info about handoffs in your agents\n",
        "- Implement Streaming With HandOff\n",
        "\n",
        "Here are some research references to get started:\n",
        "- https://openai.github.io/openai-agents-python/handoffs/\n",
        "- https://github.com/openai/openai-agents-python/blob/main/examples/handoffs/message_filter_streaming.py\n",
        "- https://github.com/openai/openai-agents-python/blob/main/examples/handoffs/message_filter.py"
      ],
      "metadata": {
        "id": "KxMKeAlTe393"
      }
    }
  ]
}